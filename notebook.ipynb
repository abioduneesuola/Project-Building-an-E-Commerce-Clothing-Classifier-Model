{"cells":[{"source":"![file-ARTHGk70atoq4sYPUICCyk5X](file-ARTHGk70atoq4sYPUICCyk5X.png)\n","metadata":{},"cell_type":"markdown","id":"660e18ce-aec5-485b-9d53-ff2b7f69ad47"},{"source":"Fashion Forward is a new AI-based e-commerce clothing retailer.\nThey want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n\nAs a data scientist tasked with implementing a garment classifier, my primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc.\n\nI will do this by using the FashionMNIST dataset class from the torchvision.datasets module. It contains images of fashion items (like shoes, shirts, etc.) used for training machine learning models. \nIt consists of:\n\n60,000 training images\n\n10,000 test images\n\nEach image is a 28x28 grayscale image of a fashion item from one of 10 categories, such as sneakers, boots, or T-shirts.","metadata":{},"id":"ad5a988c-1095-485a-a88c-002400a872be","cell_type":"markdown"},{"source":"# Run the cells below first","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1728993204030,"lastExecutedByKernel":"a0ba982a-474b-43e3-8c53-a0018fc6dfde","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run the cells below first"},"id":"4a1ab317-f3e4-4e5f-93a7-9c27677c5ffb","cell_type":"code","execution_count":2,"outputs":[]},{"source":"!pip install torchmetrics\n!pip install torchvision","metadata":{"executionCancelledAt":null,"executionTime":7249,"lastExecutedAt":1728993211279,"lastExecutedByKernel":"a0ba982a-474b-43e3-8c53-a0018fc6dfde","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install torchmetrics\n!pip install torchvision","outputsMetadata":{"0":{"height":544,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"93e7dae3-c192-4267-a0ed-18d1ac56c861","cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting torchmetrics\n  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\nCollecting lightning-utilities>=0.8.0 (from torchmetrics)\n  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\nDownloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\nInstalling collected packages: lightning-utilities, torchmetrics\nSuccessfully installed lightning-utilities-0.11.7 torchmetrics-1.4.3\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.7.99)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.6.3)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.38.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n"}]},{"source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torchmetrics import Accuracy, Precision, Recall\n\n# Creating transformations that include Data Augmentation\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n])\n\n# Loading the data\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n\n# Getting class information and setting important parameters\nclasses = train_data.classes\nnum_classes = len(classes)\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]\n\n# Defining the CNN with Batch Normalization\nclass MultiClassImageClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(num_output_channels)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten = nn.Flatten()\n        self.fc = nn.Linear(num_output_channels * (image_size // 2) ** 2, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x\n\n# DataLoader for training and test data\ndataloader_train = DataLoader(train_data, batch_size=10, shuffle=True)\ndataloader_test = DataLoader(test_data, batch_size=10, shuffle=False)\n\n# Training function with early stopping mechanism \ndef train_model(optimizer, net, num_epochs, patience):\n    criterion = nn.CrossEntropyLoss()\n    best_loss = float('inf')\n    epochs_no_improve = 0\n    for epoch in range(num_epochs):\n        net.train()\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        train_loss = running_loss / num_processed\n        print(f'epoch {epoch}, loss: {train_loss}')\n\n        # Early stopping\n        net.eval()\n        val_loss = 0\n        for features, labels in dataloader_test:\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n        val_loss /= len(dataloader_test)\n\n        if val_loss < best_loss:\n            best_loss = val_loss\n            epochs_no_improve = 0\n            best_model = net.state_dict()\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= patience:\n                print('Early stopping!')\n                net.load_state_dict(best_model)\n                break\n\n# Train the model with early stopping\nnet = MultiClassImageClassifier(num_classes)\noptimizer = optim.Adam(net.parameters(), lr=0.001)\ntrain_model(optimizer=optimizer, net=net, num_epochs=50, patience=5)\n\n# Define metrics\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n\n# Evaluating the model\nnet.eval()\npredictions = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net(features)\n    cat = torch.argmax(output, dim=-1)\n    predictions.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n\n# Computing metrics\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)\n","metadata":{},"cell_type":"code","id":"2830c310-7142-46a1-aa24-7bacc3793306","outputs":[],"execution_count":null},{"source":"The model is trained on the FashionMNIST dataset class. It is a Convolutional Neural Network that I initially trained to run for 50 epochs, but because of an early stopping function I applied, the model was able to achieve its best value at 15 epochs and didn't need to run all the way to 50. This early stopping mechanism monitors validation loss and stops training if it doesn’t improve for a certain number of epochs (the \"patience\" argument, which I set to 5).\nThis helps optimize the number of training epochs and prevent overfitting. The model achieved an accuracy of apprx 90%.","metadata":{},"cell_type":"markdown","id":"433364a6-68b6-40a6-836b-c020cb260ccc"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}